# 操作系统

**一、什么是操作系统？**

答：操作系统是软件程序。

​	BIOS在加电之后自动将操作系统代码从磁盘读入内存后运行，在这个过程中，伴随着一些数据结构的生成，它们是关于硬件设备的信息，操作系统通过它们来**感知和管理计算机硬件**。现代操作系统里说：”操作系统屏蔽掉了丑陋参差的底层细节，只为上层的应用程序提供美丽整齐的接口。”

**二、什么是系统调用？调用的流程**

答：系统调用函数是操作系统和应用程序之间的接口。

​	应用程序大多数时间运行在用户态，遇到了与系统资源相关的操作就要进入内核态，而系统调用是从用户态进入内核态的唯一合法途径，进入内核态才能使用内核指令，进而控制硬件。

应用程序函数--------系统调用函数------->库函数（能展成含有中断的代码，通过中断进入内核）------->调用内核里的指令控制硬件

**三、操作系统如何管理CPU？**

答：多进程的推进与调度。

​	每个进程都有一个存放信息的结构PCB记录它的执行情况、地址空间映射等新信息。操作系统只要把这些PCB记录好(形成队列)，按照合理的次序调度推进就形成了多进程图像，就完成了CPU的管理。CPU忙碌起来了，计算机才能快，外设硬件才能被充分带动。

**四、程序与进程的区别？**

答：程序是编译好后存放在磁盘上的固定指令序列，进程是装入内存中的执行起来的程序。

​	它们是不一样的，程序是死的静态概念，而进程能够走走停停，来回切换，有开始与结束是动态概念，并且它们的所有不一样都存放在PCB(进程控制块)这个数据结构中。

**五、进程与线程的联系与区别？**

答：一个进程中可以包含多个线程，线程像是一种轻量级的进程。

​	进程之间会发生**调度且倾向于独立**，每个进程都有自己单独的程序计数器PC，地址空间映射表，文件句柄等大量数据结构，因此进程的切换要切换上述的所有信息。地址空间分离避免了它们在内存中发生冲突。

​	线程之间也会**调度但更倾向于合作**，因此线程会共享进程范围内大量的资源。每个线程仅有自己的程序计数器PC和运行时栈及栈中的变量，线程的切换只会切换PC和栈。这些线程能访问到很多相同的变量，并在同一个堆上分配对象。

**六、线程的状态有哪些？**

答：新，就，运，阻，终。

​	以java为例。**新建状态**对应着线程对象刚刚被创建，还没有执行。此时调用线程的start()方法，会进入**就绪状态**，代表该线程开始进入就绪队列开始申请CPU时间片。当线程获得CPU时间后，它才进入**运行状态**，真正开始执行run()方法。若该线程并未结束，但由于某些原因挂起让出了CPU时间片，此时进入**阻塞状态**。线程自然结束或者执行时发生了未捕获的异常后，变为**终止状态**。

**注意：**进入阻塞状态和就绪状态的条件往往相反，如：IO的发生与返回，sleep()睡着了与睡醒了，同步锁的索要与获得，等待与收到通知。

**七、进程间通信的方式？**

答：进程可以通过 信号、信号量、管道、套接字，共享内存、消息队列的方式通信协作。

**信号**被某个进程产生，并设置此信号传递的对象(pid)，然后传递给操作系统；操作系统根据接收进程的设置（是否阻塞）而选择性的发送给接收者，目的进程接收到此信号后，保存上下文转而执行对应的中断服务程序，执行完成后再返回。

**信号量**是一些共享数据，每个进程生产或消费资源时修改信号量，信号量符合要求时进程才能推进。它用来保护临界区，以完成与其他进程之间的同步。

**管道**的实质是一个缓冲区，进程以严格的先进先出的方式从缓冲区存取数据。匿名管道是在内存中，只能在有亲缘关系的进程间通信；有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

**消息队列**是不同进程消息存放的队列，可以实现消息的随机查询**克服了**信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点

 **套接字(socket)** 是一种通信机制，客户端/服务端进程的通信既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让同一计算机上的进程通信，也可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。

**八、线程间的同步是什么、同步原则及同步方式？**

多线程完成一个任务，需要访问共享数据，彼此间这种合作需要合理有序地推进。**原则要保证：**互斥进入，有空让进，有限等待。

**信号：**某些指令的推进需要一些前提，需要其他线程发送给它一个**信号**，确保执行的正确性。线程接收到信号之前处于阻塞状态，接收到信号之后才被唤醒。

**信号量：**只发送信号不能完成多个线程之间的同步，需要用**信号量**携带更多的信息，使线程合理地运行(阻塞，调度，唤醒)

**互斥量(Mutex)**：互斥量是一把锁，某一时刻只能由一个线程持有，只有持有它的线程才有访问共享资源的权限。

**九、常见的进程调度算法？**

**FCFS:**先来先服务

**SJF:**短作业优先

**RR:**时间片轮转

一个系统肯定又有前台任务，又有后台任务，它们所需的满足不同，只能使用一种折中的方案

前台任务-IO密集型，实际运算较少，更关注响应时间优先级大
后台任务-CPU密集型，实际运算较多，更关注周转时间优先级小

**多级反馈队列：** FCFS、SJF和优先级调度算法仅对某一类任务有利，相比之下，多级反馈队列调度算法同时兼顾不同类型的任务。维护多个优先级不一样的队列，对于优先级最低的队列来说，里面是遵循**时间片轮转**法。对于其他队列，遵循的是**先来先服务**算法，每一进程分配一定的时间片，若时间片运行完时进程未结束，则进入下一优先级队列的末尾。

​	**该算法设计的精妙在于**：各个队列的时间片是随着优先级的增加而减少的优先级越高的队列中它的时间片就越短。前台任务在高优先级队列中用小时间片快速响应，后台任务在低优先级队列中用较长时间片专注于处理。

**十、什么是死锁？会引起什么后果？产生死锁的必要条件是什么？**

​	多个进程在内存中同时推进，交替执行形成了环路等待(某个进程的推进依赖一些条件，而这些条件同也依赖于它自身的推进)，或者说多个进程由于互相等待彼此所持有的资源，且都不释放自己手中的资源造成的谁也无法执行的情况。**java中**自己设计的锁导致锁的嵌套、同步代码块的粒度过大、多个功能共用使同一把锁常常会**影响性能甚至带来死锁**。很多进程无法执行处于阻塞状态，此时CPU没做正经工作因此利用率极低。

**四个必要条件：**资源互斥使用、不可抢占、保持且请求、循环等待。

**十一、处理死锁的策略？**

**死锁预防：**破坏死锁出现的条件。例如一次性申请所有资源。进程不会占有部分资源再去申请其它资源。问题是许多资源分配后很长时间才真正利用上，资源利用率较低。

**死锁避免：**检测每个资源请求，如果可能造成死锁就拒绝。每次请求出现时，假装分配给它资源，然后调用**Banker算法**，若求不出来可执行序列就意味着分配给它会带来死锁，所以千万不能分配给他！

**死锁检测和恢复：**检测到死锁出现时，让一些进程回滚让出资源。定期检查或者CPU利用率低时检测，用**Banker算法**检测出死锁的进程，让它们中的某些进程回滚。恢复比较复杂

**死锁忽略：**全然不顾，进程卡死就卡死，太卡了就重启。PC上死锁忽略的处理代价很小，进程少出现死锁的概率也很低，因此是非常实惠的，但是在服务器上不行。

**十二、操作系统如何管理内存？**

​	**内存是为进程服务的**，在程序变为进程的那一刻开始就伴随着代码和数据装入内存，进程运行或者调度都伴随着内存中数据的装入或者换出。为了使进程执行的更流畅，采用虚拟内存、分段分页，快表等机制以及合理的页面替换算法来提高内存空间的利用率和访问内存的速度，这就完成了内存管理的主要内容。

**十三、内存管理机制有哪些？**

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为每个用户程序分配一个连续的内存空间如**分区管理** 。同样地，非连续分配管理方式允许程序使用的内存分布在离散或者说不相邻的内存中，常见的如**分页管理**和**分段管理**。

**分区机制：**将内存分为一个个区，如果进程需要内存的话，操作系统就分配给它一个连续分区。这会造成内存的碎片化-总空间够用，但是没有一块完整的连续地址处理新的内存请求，可能需要内存紧缩移动。非常非常耗时

**分段机制：**程序不是整个装入内存的，而是分成好几个段，每个段都有各自的特点：代码段只读，数据段可写，栈会动态增长，将各个段分别放入内存以便用户分开治理使用。进程的PCB中的段表(**局部描述符表LDT**)对应了该进程的多个段分别存放于内存中的何处。

**分页机制：**将程序和内存都分成一页一页的，将面包切成片，从连续变成离散最大的浪费不过4K。划分力度更大，提高了内存利用率，减少了碎片。进程PCB中有属于自己的**页表**，管理逻辑页到物理页的映射。

**十四、** **分页机制和分段机制有哪些共同点和区别？**

**共同点**

- 页和段都是内存管理机制中引入的概念，两者都是离散分配内存的方式。但每个页和段中的内存是连续的，可以通过基址加偏移寻址

**区别**

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
- 分页仅仅是为了操作系统向下对真实物理内存管理的需求。而段是带有逻辑信息单位，在程序中可以体现为代码段，数据段，能够更好向上满足用户的需要。

**十五、虚拟内存和段页结合式机制？**   

**OS要向用户程序提供分段机制，又要向实际内存提供分页机制。所以引入虚拟内存**
因此要在虚拟内存中选取合适的区域放入程序的各个段，并生成进程的**LDT**表示上述映射关系。虚拟内存的地址空间需要分页，每个页对应于真实物理内存中的页框，由进程的**页表**这个映射关系。

​	**流程：**

​	运行过程中某条指令中含有地址值(**逻辑地址**)需要重定位，用这条指令的段号查段基址，加上段内偏移组成段地址(**虚拟地址**)，用虚拟地址的页号查页表得到页框号，加上页内偏移得到真实的**物理地址**。运行时重定位完毕，指令得以正常运行，进程得以推进，也正是在进程推进的过程中带动了内存的使用。**注意，因为我们有段表和页表，MMU可以自主完成上述计算。**

十五、？









